{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先定义消息函数和累和函数\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        if self.activation is not None:\n",
    "            h = self.activation(h)\n",
    "        return {'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(1433, 16, F.relu)\n",
    "        self.gcn2 = GCN(16, 7, None)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gcn1): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gcn2): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "import networkx as nx\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = th.FloatTensor(data.features)\n",
    "    labels = th.LongTensor(data.labels)\n",
    "    train_mask = th.BoolTensor(data.train_mask)\n",
    "    test_mask = th.BoolTensor(data.test_mask)\n",
    "    g = data.graph\n",
    "    g.remove_edges_from(nx.selfloop_edges(g))\n",
    "    g = DGLGraph(g)\n",
    "    g.add_edges(g.nodes(), g.nodes())\n",
    "    return g, features, labels, train_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, g, features, labels, mask):\n",
    "    model.eval()\n",
    "    with th.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = th.max(logits, dim=1)\n",
    "        correct = th.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "g, features, labels, train_mask, test_mask = load_cora_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Tree/opt/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/Tree/opt/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 2.0009 | Test Acc 0.1540 | Time(s) nan\n",
      "Epoch 00001 | Loss 1.9728 | Test Acc 0.1880 | Time(s) nan\n",
      "Epoch 00002 | Loss 1.9468 | Test Acc 0.2080 | Time(s) nan\n",
      "Epoch 00003 | Loss 1.9202 | Test Acc 0.2070 | Time(s) 0.0165\n",
      "Epoch 00004 | Loss 1.8928 | Test Acc 0.2200 | Time(s) 0.0159\n",
      "Epoch 00005 | Loss 1.8649 | Test Acc 0.2410 | Time(s) 0.0156\n",
      "Epoch 00006 | Loss 1.8365 | Test Acc 0.2570 | Time(s) 0.0156\n",
      "Epoch 00007 | Loss 1.8073 | Test Acc 0.2780 | Time(s) 0.0156\n",
      "Epoch 00008 | Loss 1.7774 | Test Acc 0.2910 | Time(s) 0.0159\n",
      "Epoch 00009 | Loss 1.7473 | Test Acc 0.3100 | Time(s) 0.0161\n",
      "Epoch 00010 | Loss 1.7178 | Test Acc 0.3270 | Time(s) 0.0160\n",
      "Epoch 00011 | Loss 1.6887 | Test Acc 0.3560 | Time(s) 0.0159\n",
      "Epoch 00012 | Loss 1.6601 | Test Acc 0.3910 | Time(s) 0.0158\n",
      "Epoch 00013 | Loss 1.6322 | Test Acc 0.4370 | Time(s) 0.0158\n",
      "Epoch 00014 | Loss 1.6048 | Test Acc 0.4630 | Time(s) 0.0157\n",
      "Epoch 00015 | Loss 1.5781 | Test Acc 0.4810 | Time(s) 0.0156\n",
      "Epoch 00016 | Loss 1.5523 | Test Acc 0.4960 | Time(s) 0.0156\n",
      "Epoch 00017 | Loss 1.5274 | Test Acc 0.5100 | Time(s) 0.0155\n",
      "Epoch 00018 | Loss 1.5034 | Test Acc 0.5250 | Time(s) 0.0153\n",
      "Epoch 00019 | Loss 1.4800 | Test Acc 0.5300 | Time(s) 0.0152\n",
      "Epoch 00020 | Loss 1.4574 | Test Acc 0.5330 | Time(s) 0.0151\n",
      "Epoch 00021 | Loss 1.4352 | Test Acc 0.5400 | Time(s) 0.0150\n",
      "Epoch 00022 | Loss 1.4137 | Test Acc 0.5460 | Time(s) 0.0149\n",
      "Epoch 00023 | Loss 1.3928 | Test Acc 0.5490 | Time(s) 0.0148\n",
      "Epoch 00024 | Loss 1.3723 | Test Acc 0.5510 | Time(s) 0.0147\n",
      "Epoch 00025 | Loss 1.3524 | Test Acc 0.5550 | Time(s) 0.0147\n",
      "Epoch 00026 | Loss 1.3330 | Test Acc 0.5600 | Time(s) 0.0146\n",
      "Epoch 00027 | Loss 1.3141 | Test Acc 0.5680 | Time(s) 0.0146\n",
      "Epoch 00028 | Loss 1.2958 | Test Acc 0.5740 | Time(s) 0.0145\n",
      "Epoch 00029 | Loss 1.2779 | Test Acc 0.5740 | Time(s) 0.0144\n",
      "Epoch 00030 | Loss 1.2606 | Test Acc 0.5810 | Time(s) 0.0144\n",
      "Epoch 00031 | Loss 1.2436 | Test Acc 0.5810 | Time(s) 0.0143\n",
      "Epoch 00032 | Loss 1.2272 | Test Acc 0.5890 | Time(s) 0.0143\n",
      "Epoch 00033 | Loss 1.2111 | Test Acc 0.5970 | Time(s) 0.0142\n",
      "Epoch 00034 | Loss 1.1955 | Test Acc 0.6000 | Time(s) 0.0142\n",
      "Epoch 00035 | Loss 1.1803 | Test Acc 0.6030 | Time(s) 0.0142\n",
      "Epoch 00036 | Loss 1.1655 | Test Acc 0.6110 | Time(s) 0.0142\n",
      "Epoch 00037 | Loss 1.1510 | Test Acc 0.6150 | Time(s) 0.0141\n",
      "Epoch 00038 | Loss 1.1369 | Test Acc 0.6270 | Time(s) 0.0141\n",
      "Epoch 00039 | Loss 1.1232 | Test Acc 0.6370 | Time(s) 0.0140\n",
      "Epoch 00040 | Loss 1.1098 | Test Acc 0.6400 | Time(s) 0.0140\n",
      "Epoch 00041 | Loss 1.0967 | Test Acc 0.6420 | Time(s) 0.0140\n",
      "Epoch 00042 | Loss 1.0839 | Test Acc 0.6460 | Time(s) 0.0140\n",
      "Epoch 00043 | Loss 1.0713 | Test Acc 0.6540 | Time(s) 0.0140\n",
      "Epoch 00044 | Loss 1.0590 | Test Acc 0.6560 | Time(s) 0.0140\n",
      "Epoch 00045 | Loss 1.0469 | Test Acc 0.6620 | Time(s) 0.0140\n",
      "Epoch 00046 | Loss 1.0351 | Test Acc 0.6680 | Time(s) 0.0139\n",
      "Epoch 00047 | Loss 1.0235 | Test Acc 0.6690 | Time(s) 0.0139\n",
      "Epoch 00048 | Loss 1.0121 | Test Acc 0.6740 | Time(s) 0.0139\n",
      "Epoch 00049 | Loss 1.0010 | Test Acc 0.6790 | Time(s) 0.0139\n"
     ]
    }
   ],
   "source": [
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "dur = []\n",
    "for epoch in range(50):\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    net.train()\n",
    "    logits = net(g, features)\n",
    "    logp = F.log_softmax(logits, 1)\n",
    "    loss = F.nll_loss(logp[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "\n",
    "    acc = evaluate(net, g, features, labels, test_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Test Acc {:.4f} | Time(s) {:.4f}\".format(\n",
    "            epoch, loss.item(), acc, np.mean(dur)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
